{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pink\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as  np\n",
    "import pandas as pd\n",
    "from random import seed, random\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[[[i+1+j] for i in range(3)] for j in range(4)]\n",
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=[(i+4) for i in range(4)]\n",
    "target=np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1],\n",
       "         [2],\n",
       "         [3]],\n",
       " \n",
       "        [[2],\n",
       "         [3],\n",
       "         [4]],\n",
       " \n",
       "        [[3],\n",
       "         [4],\n",
       "         [5]],\n",
       " \n",
       "        [[4],\n",
       "         [5],\n",
       "         [6]]]), array([4, 5, 6, 7]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data --> (4, 3, 1) \n",
      "Shape of target--> (4,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data -->',data.shape,'\\nShape of target-->',target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidPrime(output):\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward-Propogation in RNN\n",
    "#### How it's Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of hidden_dim is--> 10 \n",
      "Shape of input_dim is--> 3 \n",
      "Shape of input_dim is--> 1\n"
     ]
    }
   ],
   "source": [
    "test=data[0]\n",
    "hidden_dim=10\n",
    "#input_dim = data.shape[1]\n",
    "input_dim = data.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "print('Shape of hidden_dim is-->',hidden_dim,'\\nShape of input_dim is-->',data.shape[1],'\\nShape of input_dim is-->',1)\n",
    "wxh = 2*np.random.random((hidden_dim,input_dim)) - 1\n",
    "whh = 2*np.random.random((hidden_dim,hidden_dim)) - 1\n",
    "why = 2*np.random.random((hidden_dim,output_dim)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### it is a previous state you may called it 0-State\n",
    "hprev=np.zeros(hidden_dim)\n",
    "hprev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os_0 equals to [[0.44286146]]\n",
      "os_1 equals to [[0.47999096]]\n",
      "os_2 equals to [[0.4510859]]\n",
      "os_3 equals to [[0.45500739]]\n",
      "-------------------Above and Below sequences are same this is how RNN Works-----------------\n",
      "[0.44286146 0.47999096 0.4510859  0.45500739]\n"
     ]
    }
   ],
   "source": [
    "## When data=data[0]\n",
    "\"\"\"\n",
    " Input=1,2,3\n",
    " Target=4\n",
    "\"\"\"\n",
    "\n",
    "xs_0=sigmoid(np.dot(wxh,data[0])+np.dot(whh,hprev).reshape(hidden_dim,1))\n",
    "os_0=sigmoid(np.dot(why.T,xs_0))\n",
    "print('os_0 equals to',os_0)\n",
    "\n",
    "## When data=data[1]\n",
    "\n",
    "\"\"\"\n",
    " Input=2,3,4\n",
    " Target=5\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "xs_1=sigmoid(np.dot(wxh,data[1])+np.dot(whh,xs_0).reshape(hidden_dim,1))\n",
    "os_1=sigmoid(np.dot(why.T,xs_1))\n",
    "print('os_1 equals to',os_1)\n",
    "\n",
    "\n",
    "## When data=data[2]\n",
    "\n",
    "\"\"\"\n",
    " Input=3,4,5\n",
    " Target=6\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "xs_2=sigmoid(np.dot(wxh,data[2])+np.dot(whh,xs_1).reshape(hidden_dim,1))\n",
    "os_2=sigmoid(np.dot(why.T,xs_2))\n",
    "print('os_2 equals to',os_2)\n",
    "\n",
    "## When data=data[3]\n",
    "\n",
    "\"\"\"\n",
    " Input=4,5,6\n",
    " Target=7\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "xs_3=sigmoid(np.dot(wxh,data[3])+np.dot(whh,xs_2).reshape(hidden_dim,1))\n",
    "os_3=sigmoid(np.dot(why.T,xs_3))\n",
    "print('os_3 equals to',os_3)\n",
    "\n",
    "T=len(data)\n",
    "xs = np.zeros((T,hidden_dim))\n",
    "os= np.zeros(len(data))\n",
    "xs = np.zeros((T,hidden_dim))\n",
    "xs[-1]=np.zeros((hidden_dim))\n",
    "os = np.zeros((len(data),1))\n",
    "os= np.zeros(len(data))\n",
    "print('-------------------Above and Below sequences are same this is how RNN Works-----------------')\n",
    "for i in range(len(data)):\n",
    "    xs[i]=sigmoid(np.dot(wxh,data[i])+(np.dot(whh,xs[i-1])).reshape(hidden_dim,1)).reshape(hidden_dim)\n",
    "    os[i]=sigmoid(np.dot(why.T,xs[i]))\n",
    "print(os)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Code is Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNNSeq(lr,epoch):\n",
    "    \n",
    "    \n",
    "    hidden_dim=10\n",
    "    input_dim = data.shape[1]\n",
    "    output_dim = 1\n",
    "\n",
    "    \"\"\"\n",
    "    Total Number of T is equal to length of data and we are adding one because we need to consider initial state\n",
    "    which is all zero.\n",
    "    int_s is a initial state also know as (h0)\n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    np.random.seed(1)\n",
    "    wxh = 2*np.random.random((hidden_dim,input_dim)) - 1\n",
    "    whh = 2*np.random.random((hidden_dim,hidden_dim)) - 1\n",
    "    why = 2*np.random.random((hidden_dim,output_dim)) - 1\n",
    "\n",
    "    T = len(data)\n",
    "\n",
    "    xs = np.zeros((T,hidden_dim))\n",
    "    xs[-1]=np.zeros((hidden_dim))\n",
    "    os = np.zeros((len(data),1))\n",
    "    os= np.zeros(len(data))\n",
    "\n",
    "    ### Starting of Gradient descent\n",
    "    for ep in range(epoch):\n",
    "        \n",
    "        ### Run the code equals to length of data\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            \n",
    "            \"\"\" \n",
    "            ## Reshape is just broadcasting of Data\n",
    "            Basically xs[i]=sigmoid(np.dot(wxh,data[i])+(np.dot(whh,xs[i-1])))\n",
    "\n",
    "            \"\"\" \n",
    "            xs[i]=sigmoid(np.dot(wxh,data[i])+(np.dot(whh,xs[i-1])).reshape(hidden_dim,1)).reshape(hidden_dim)\n",
    "\n",
    "            os[i]=sigmoid(np.dot(why.T,xs[i]))\n",
    "\n",
    "            cost=np.sum((os[i]-target)**2)/2\n",
    "\n",
    "            \"\"\"\n",
    "            Back-propogation through Time starts here\n",
    "\n",
    "            Using Gradient Descent\n",
    "\n",
    "            backward pass: compute gradients going backwards    \n",
    "            initalize vectors for gradient values for each set of weights \n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            djdwhy=((os[i]-target[i])*sigmoidPrime(os[i])*xs[i]).reshape(hidden_dim,1)\n",
    "\n",
    "            djdwxh=((os[i]-target[i])*sigmoidPrime(os[i])*why)*sigmoidPrime(xs[i]).reshape(hidden_dim,1)*data[i].T\n",
    "\n",
    "            djdwhh=(((os[i]-target[i])*sigmoidPrime(os[i])*why)*sigmoidPrime(xs[i]).reshape(hidden_dim,1))*(xs[i-1].reshape(hidden_dim,1))\n",
    "\n",
    "\n",
    "            ## SGD of why\n",
    "            why=why-lr*djdwhy\n",
    "\n",
    "            ## SGD of wxh\n",
    "            wxh=wxh-lr*djdwxh\n",
    "\n",
    "            ## SGD of whh\n",
    "            whh=whh-lr*djdwhh\n",
    "            \n",
    "            \n",
    "            # Assign new parameters to the model\n",
    "            \n",
    "            model={}\n",
    "            \n",
    "            model = {'Iteration':ep,'RMSE Loss':cost,'why': why,'whh': whh,'whx':wxh}\n",
    "            \n",
    "        if ep%400 ==0:\n",
    "                \n",
    "            print('Iteration =',ep,'\\n','RMSE Loss',cost,'\\n','why','\\n',why,'\\n','whh','\\n',whh,'\\n','wxh','\\n',wxh)\n",
    "            print('------------------------------------------------------------------------------------------')\n",
    "                \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 0 \n",
      " RMSE Loss 56.53440780299797 \n",
      " why \n",
      " [[ 0.17171067]\n",
      " [ 0.93920592]\n",
      " [ 0.12219894]\n",
      " [-0.95876846]\n",
      " [ 0.60157885]\n",
      " [-0.53008676]\n",
      " [ 0.61507092]\n",
      " [-0.21989884]\n",
      " [ 0.73099304]\n",
      " [ 0.49515369]] \n",
      " whh \n",
      " [[-0.80330488 -0.1577833   0.91578051  0.06633202  0.38375568 -0.36896729\n",
      "   0.37300331  0.66925279 -0.963422    0.50029008]\n",
      " [ 0.9777222   0.49633133 -0.43911199  0.57855868 -0.79354796 -0.10421292\n",
      "   0.81719103 -0.41277168 -0.4244493  -0.73994283]\n",
      " [-0.96126583  0.35767132 -0.57674351 -0.46890642 -0.01685342 -0.89327465\n",
      "   0.14823547 -0.70654259  0.17861133  0.39951698]\n",
      " [-0.79561453 -0.17217141  0.38851693 -0.17192485 -0.90037647  0.07150942\n",
      "   0.3273059   0.02949483  0.88890612  0.17282669]\n",
      " [ 0.80681625 -0.72503817 -0.72143489  0.614795   -0.20463391 -0.66927919\n",
      "   0.85502958 -0.30445586  0.50163662  0.45200839]\n",
      " [ 0.76650356  0.24723579  0.50177624 -0.30231194 -0.46025284  0.79166381\n",
      "  -0.14392625  0.92957147  0.32677437  0.24328281]\n",
      " [-0.77042754  0.89905903 -0.10009522  0.15685974 -0.18364588 -0.52586553\n",
      "   0.80683955  0.14743948 -0.99417884  0.23437034]\n",
      " [-0.34672118  0.05410522  0.77187322 -0.28547146  0.81705932  0.24670925\n",
      "  -0.9683685   0.85886349  0.38178285  0.99463472]\n",
      " [-0.65522334 -0.72563285  0.86528657  0.39373197 -0.86790401  0.51102175\n",
      "   0.50784802  0.84614472  0.42314516 -0.75136243]\n",
      " [-0.96017355 -0.94751184 -0.94332084 -0.50751168  0.72012208  0.07772831\n",
      "   0.10571014  0.68412797 -0.75158718 -0.44156646]] \n",
      " wxh \n",
      " [[-0.16589993  0.44073569 -0.99965391]\n",
      " [-0.39531916 -0.70645914 -0.81528036]\n",
      " [-0.62746138 -0.30884541 -0.20641696]\n",
      " [ 0.07643894 -0.16333788  0.36817971]\n",
      " [-0.59075253  0.75674798 -0.94454157]\n",
      " [ 0.34042111 -0.16616076  0.11635284]\n",
      " [-0.71853808 -0.60275524  0.60288466]\n",
      " [ 0.93645923 -0.37326071  0.38449101]\n",
      " [ 0.75332183  0.79006987 -0.82874202]\n",
      " [-0.92126507 -0.65941304  0.75751189]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Iteration = 400 \n",
      " RMSE Loss 43.42479545476925 \n",
      " why \n",
      " [[ 0.197476  ]\n",
      " [ 0.94028805]\n",
      " [ 0.13049747]\n",
      " [-0.60079912]\n",
      " [ 0.70331699]\n",
      " [ 0.12373889]\n",
      " [ 0.88452175]\n",
      " [ 0.49052527]\n",
      " [ 1.41781236]\n",
      " [ 0.83436511]] \n",
      " whh \n",
      " [[-0.80310424 -0.15758266  0.91598115  0.06653266  0.38395632 -0.36876665\n",
      "   0.37320394  0.66945343 -0.96322136  0.50049072]\n",
      " [ 0.97772334  0.49633247 -0.43911085  0.57855982 -0.79354682 -0.10421178\n",
      "   0.81719217 -0.41277054 -0.42444816 -0.73994169]\n",
      " [-0.96125309  0.35768406 -0.57673077 -0.46889368 -0.01684068 -0.89326191\n",
      "   0.14824821 -0.70652985  0.17862407  0.39952972]\n",
      " [-0.8448317  -0.22138858  0.33929976 -0.22114202 -0.94959364  0.02229225\n",
      "   0.27808873 -0.01972234  0.83968895  0.12360952]\n",
      " [ 0.81730484 -0.71454958 -0.71094629  0.62528359 -0.19414531 -0.65879059\n",
      "   0.86551817 -0.29396727  0.51212522  0.46249698]\n",
      " [ 0.75585122  0.23658345  0.49112391 -0.31296428 -0.47090518  0.78101147\n",
      "  -0.15457858  0.91891913  0.31612203  0.23263048]\n",
      " [-0.73312609  0.93636048 -0.06279377  0.19416119 -0.14634443 -0.48856407\n",
      "   0.84414101  0.18474094 -0.95687738  0.27167179]\n",
      " [-0.34537192  0.05545448  0.77322248 -0.2841222   0.81840858  0.24805851\n",
      "  -0.96701923  0.86021275  0.38313211  0.99598398]\n",
      " [-0.62196863 -0.69237814  0.89854128  0.42698668 -0.8346493   0.54427646\n",
      "   0.54110274  0.87939943  0.45639988 -0.71810772]\n",
      " [-0.91861624 -0.90595453 -0.90176353 -0.46595437  0.76167939  0.11928563\n",
      "   0.14726745  0.72568528 -0.71002987 -0.40000915]] \n",
      " wxh \n",
      " [[-0.15683255  0.45428495 -0.98162277]\n",
      " [-0.39408339 -0.7042126  -0.81202303]\n",
      " [-0.62586014 -0.30622792 -0.20278323]\n",
      " [-0.16692572 -0.49944626 -0.06067239]\n",
      " [-0.47166098  0.92687838 -0.72337231]\n",
      " [ 0.31050861 -0.20785093  0.06288501]\n",
      " [-0.50604162 -0.30755978  0.98077912]\n",
      " [ 0.93877537 -0.36957544  0.38954543]\n",
      " [ 0.82075239  0.89289745 -0.69051743]\n",
      " [-0.71280223 -0.37222448  1.12342617]]\n",
      "------------------------------------------------------------------------------------------\n",
      "Iteration = 800 \n",
      " RMSE Loss 43.179715506268735 \n",
      " why \n",
      " [[ 0.20501218]\n",
      " [ 0.9404229 ]\n",
      " [ 0.13268901]\n",
      " [-0.58465816]\n",
      " [ 0.7634658 ]\n",
      " [ 0.22854254]\n",
      " [ 0.98846576]\n",
      " [ 0.60619815]\n",
      " [ 1.52956018]\n",
      " [ 0.94115626]] \n",
      " whh \n",
      " [[-0.80301191 -0.15749033  0.91607348  0.06662499  0.38404865 -0.36867432\n",
      "   0.37329627  0.66954576 -0.96312903  0.50058305]\n",
      " [ 0.97772343  0.49633256 -0.43911076  0.57855991 -0.79354673 -0.10421169\n",
      "   0.81719226 -0.41277045 -0.42444807 -0.7399416 ]\n",
      " [-0.96124895  0.3576882  -0.57672663 -0.46888954 -0.01683654 -0.89325777\n",
      "   0.14825235 -0.70652571  0.17862821  0.39953386]\n",
      " [-0.84588402 -0.2224409   0.33824744 -0.22219434 -0.95064596  0.02123993\n",
      "   0.27703641 -0.02077465  0.83863664  0.1225572 ]\n",
      " [ 0.82816902 -0.7036854  -0.70008212  0.63614777 -0.18328114 -0.64792642\n",
      "   0.87638235 -0.28310309  0.52298939  0.47336116]\n",
      " [ 0.75759298  0.23832521  0.49286566 -0.31122252 -0.46916342  0.78275323\n",
      "  -0.15283682  0.92066089  0.31786379  0.23437224]\n",
      " [-0.72347117  0.9460154  -0.05313885  0.20381611 -0.13668951 -0.47890916\n",
      "   0.85379592  0.19439586 -0.94722246  0.28132671]\n",
      " [-0.34453364  0.05629276  0.77406076 -0.28328392  0.81924686  0.24889679\n",
      "  -0.96618096  0.86105103  0.38397039  0.99682226]\n",
      " [-0.61492514 -0.68533466  0.90558477  0.43403016 -0.82760581  0.55131995\n",
      "   0.54814622  0.88644291  0.46344336 -0.71106424]\n",
      " [-0.91098885 -0.89832714 -0.89413614 -0.45832698  0.76930678  0.12691301\n",
      "   0.15489484  0.73331267 -0.70240248 -0.39238176]] \n",
      " wxh \n",
      " [[-0.15414999  0.45834108 -0.97619307]\n",
      " [-0.39392983 -0.7039327  -0.8116168 ]\n",
      " [-0.62545281 -0.30554534 -0.20182542]\n",
      " [-0.18168481 -0.52162816 -0.0902771 ]\n",
      " [-0.41651615  1.00285258 -0.62656874]\n",
      " [ 0.31535909 -0.20104576  0.07164486]\n",
      " [-0.47933133 -0.26991536  1.02935766]\n",
      " [ 0.94015412 -0.36734741  0.39262273]\n",
      " [ 0.83298236  0.91251687 -0.66350854]\n",
      " [-0.691378   -0.34239928  1.16165234]]\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Iteration': 1199,\n",
       " 'RMSE Loss': 43.11317567574103,\n",
       " 'why': array([[ 0.20972528],\n",
       "        [ 0.94048867],\n",
       "        [ 0.13396726],\n",
       "        [-0.57751604],\n",
       "        [ 0.80744916],\n",
       "        [ 0.28621659],\n",
       "        [ 1.0473676 ],\n",
       "        [ 0.66986619],\n",
       "        [ 1.59083792],\n",
       "        [ 1.0015603 ]]),\n",
       " 'whh': array([[-0.80294759, -0.15742601,  0.9161378 ,  0.06668931,  0.38411297,\n",
       "         -0.36861   ,  0.37336059,  0.66961008, -0.96306471,  0.50064737],\n",
       "        [ 0.97772347,  0.4963326 , -0.43911072,  0.57855995, -0.79354669,\n",
       "         -0.10421165,  0.8171923 , -0.41277041, -0.42444803, -0.73994156],\n",
       "        [-0.96124649,  0.35769066, -0.57672417, -0.46888709, -0.01683409,\n",
       "         -0.89325531,  0.14825481, -0.70652325,  0.17863067,  0.39953632],\n",
       "        [-0.84624861, -0.22280549,  0.33788285, -0.22255893, -0.95101055,\n",
       "          0.02087535,  0.27667182, -0.02113924,  0.83827205,  0.12219261],\n",
       "        [ 0.8355989 , -0.69625553, -0.69265224,  0.64357764, -0.17585126,\n",
       "         -0.64049654,  0.88381223, -0.27567321,  0.53041927,  0.48079104],\n",
       "        [ 0.7589776 ,  0.23970983,  0.49425029, -0.3098379 , -0.4677788 ,\n",
       "          0.78413786, -0.1514522 ,  0.92204552,  0.31924842,  0.23575686],\n",
       "        [-0.71881922,  0.95066735, -0.0484869 ,  0.20846806, -0.13203756,\n",
       "         -0.4742572 ,  0.85844788,  0.19904781, -0.94257051,  0.28597866],\n",
       "        [-0.3440626 ,  0.0567638 ,  0.77453179, -0.28281289,  0.8197179 ,\n",
       "          0.24936782, -0.96570992,  0.86152206,  0.38444143,  0.99729329],\n",
       "        [-0.61069368, -0.6811032 ,  0.90981623,  0.43826162, -0.82337435,\n",
       "          0.55555141,  0.55237768,  0.89067437,  0.46767482, -0.70683278],\n",
       "        [-0.90756762, -0.89490591, -0.89071491, -0.45490575,  0.77272801,\n",
       "          0.13033424,  0.15831607,  0.7367339 , -0.69898125, -0.38896053]]),\n",
       " 'whx': array([[-0.15246543,  0.46089933, -0.97276113],\n",
       "        [-0.39385456, -0.70379578, -0.81141823],\n",
       "        [-0.62521552, -0.30514563, -0.20126327],\n",
       "        [-0.18797698, -0.53130139, -0.10333139],\n",
       "        [-0.38817671,  1.04208514, -0.57644307],\n",
       "        [ 0.31910682, -0.19574868,  0.07849129],\n",
       "        [-0.46761774, -0.25310726,  1.05126027],\n",
       "        [ 0.94092229, -0.36610299,  0.39434341],\n",
       "        [ 0.8399923 ,  0.92395719, -0.64763784],\n",
       "        [-0.6824564 , -0.32982271,  1.17788387]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNNSeq(lr=.001,epoch=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
