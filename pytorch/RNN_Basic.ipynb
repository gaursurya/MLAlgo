{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Basic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMDrE6Uz2lG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F \n",
        "\n",
        "from torchtext import datasets\n",
        "from torchtext.data import Field\n",
        "from torchtext import data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI3-CwGlIOHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!mkdir data\n",
        "#!wget -c https://github.com/agungsantoso/deep-learning-v2-pytorch/raw/master/sentiment-rnn/data/labels.txt\n",
        "#!wget -c https://github.com/agungsantoso/deep-learning-v2-pytorch/raw/master/sentiment-rnn/data/reviews.txt\n",
        "#!mv *.txt data/\n",
        "#import numpy as np\n",
        "#with open('data/reviews.txt', 'r') as f:\n",
        "#     reviews = f.readlines()\n",
        "#with open('data/labels.txt', 'r') as f:\n",
        "#     labels = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8WTlgiyhRiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##import pandas as pd\n",
        "\n",
        "##df =pd.concat([pd.DataFrame(reviews,columns=['reviews']),pd.DataFrame(labels,columns=['labels'])],axis=1)\n",
        "#del reviews,labels\n",
        "\n",
        "#############\n",
        "#df['labels'] = np.where(df['labels']=='positive\\n', 1,0)\n",
        "#df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uh2v4ll1g4X",
        "colab_type": "code",
        "outputId": "5a5cbc64-a352-4459-a93a-a884e34dbae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "text = ['good movies'\n",
        ",'awfull movie'\n",
        ",'very good movie to watch'\n",
        ",'very good movie to watch on weekends'\n",
        ",'awfull movie wasted my money'\n",
        ",'awfull movie wasted my money and time probably do something better'\n",
        ",'great movie to watch anytime really good movie enjoy a lot'\n",
        ",'awfull awfull awfull awfull movies wasted wasted wasted money money money'\n",
        ",'bad movie awfully bad'\n",
        ",'great movie but awfull acting really enjoy but wasted money']\n",
        "\n",
        "label = [1,0,1,1,0,0,1,0,0,1]\n",
        "print('length of text',len(text))\n",
        "print('length of label',len(label))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of text 10\n",
            "length of label 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zlPaJzRFEcr",
        "colab_type": "code",
        "outputId": "2e81d57d-9cc9-49c6-d435-0ea1abb64e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "from string import punctuation\n",
        "all_text = '\\n'.join([c for c in text if c not in punctuation])\n",
        "print(all_text)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "good movies\n",
            "awfull movie\n",
            "very good movie to watch\n",
            "very good movie to watch on weekends\n",
            "awfull movie wasted my money\n",
            "awfull movie wasted my money and time probably do something better\n",
            "great movie to watch anytime really good movie enjoy a lot\n",
            "awfull awfull awfull awfull movies wasted wasted wasted money money money\n",
            "bad movie awfully bad\n",
            "great movie but awfull acting really enjoy but wasted money\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJInVHTjKGM2",
        "colab_type": "code",
        "outputId": "6462fec7-2c48-4333-d5cf-4b9ad3748094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "all_text.split('\\n')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good movies',\n",
              " 'awfull movie',\n",
              " 'very good movie to watch',\n",
              " 'very good movie to watch on weekends',\n",
              " 'awfull movie wasted my money',\n",
              " 'awfull movie wasted my money and time probably do something better',\n",
              " 'great movie to watch anytime really good movie enjoy a lot',\n",
              " 'awfull awfull awfull awfull movies wasted wasted wasted money money money',\n",
              " 'bad movie awfully bad',\n",
              " 'great movie but awfull acting really enjoy but wasted money']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BZUjFSiGfHl",
        "colab_type": "code",
        "outputId": "5661c051-8ebe-4dd5-abfc-7732e57c16d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "all_text_1 = ' '.join(all_text.split('\\n'))\n",
        "words = all_text_1.split()\n",
        "count_words = Counter(words)\n",
        "total_words = len(words)\n",
        "sorted_words = count_words.most_common(total_words)\n",
        "\n",
        "vocab_size = len(sorted_words)\n",
        "print('Vocab size',vocab_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_74a46LG7LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_to_int = {w:i + 1 for i, (w,c) in enumerate(sorted_words)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdA2raHyHm96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Creating Encoded data\n",
        "text_encoded = list()\n",
        "for review in all_text.split('\\n'):\n",
        "  i_x = [char_to_int[w] for w in review.split()]\n",
        "  text_encoded.append(i_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH7GKftCH-0R",
        "colab_type": "code",
        "outputId": "acb1729c-f2e0-4e45-ac8b-6e98f414c948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "text_encoded"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 8],\n",
              " [2, 1],\n",
              " [9, 5, 1, 6, 7],\n",
              " [9, 5, 1, 6, 7, 16, 17],\n",
              " [2, 1, 3, 10, 4],\n",
              " [2, 1, 3, 10, 4, 18, 19, 20, 21, 22, 23],\n",
              " [11, 1, 6, 7, 24, 12, 5, 1, 13, 25, 26],\n",
              " [2, 2, 2, 2, 8, 3, 3, 3, 4, 4, 4],\n",
              " [14, 1, 27, 14],\n",
              " [11, 1, 15, 2, 28, 12, 13, 15, 3, 4]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4G1e73iJFGl",
        "colab_type": "code",
        "outputId": "9c4504f6-bbea-4cb6-a99f-df038fcb30a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "text_encoded_padded = pad_sequences(text_encoded, padding='pre')\n",
        "text_encoded_padded"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  8],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0,  9,  5,  1,  6,  7],\n",
              "       [ 0,  0,  0,  0,  9,  5,  1,  6,  7, 16, 17],\n",
              "       [ 0,  0,  0,  0,  0,  0,  2,  1,  3, 10,  4],\n",
              "       [ 2,  1,  3, 10,  4, 18, 19, 20, 21, 22, 23],\n",
              "       [11,  1,  6,  7, 24, 12,  5,  1, 13, 25, 26],\n",
              "       [ 2,  2,  2,  2,  8,  3,  3,  3,  4,  4,  4],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0, 14,  1, 27, 14],\n",
              "       [ 0, 11,  1, 15,  2, 28, 12, 13, 15,  3,  4]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjDg1SbnJhmi",
        "colab_type": "code",
        "outputId": "8056b611-2a34-4c54-adae-1ed1ffe92cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "input_feature = Variable(torch.Tensor(text_encoded_padded).long())\n",
        "label_tensor = Variable(torch.Tensor(label).float())\n",
        "print('shape of Input',input_feature.shape)\n",
        "print('shape of output',label_tensor.shape)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of Input torch.Size([10, 11])\n",
            "shape of output torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9gwRwKQZm4M",
        "colab_type": "code",
        "outputId": "99bf242b-7f6c-4759-a67d-258054645935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "label_tensor"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 1., 1., 0., 0., 1., 0., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goSwh4nQQqjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### building RNN (many-to-one)\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  '''\n",
        "      1. nn.Embedding\n",
        "      Input: batch_size x seq_length\n",
        "      Output: batch-size x seq_length x embedding_dimension\n",
        "\n",
        "      2. nn.LSTM\n",
        "      Input: seq_length x batch_size x input_size (embedding_dimension in this case)\n",
        "      Output: seq_length x batch_size x hidden_size\n",
        "      last_hidden_state: batch_size, hidden_size\n",
        "      last_cell_state: batch, hidden_size\n",
        "      \n",
        "      3. nn.Linear\n",
        "      Input: batch_size x input_size (hidden_size of LSTM in this case or ??)\n",
        "      Output: batch_size x output_size\n",
        " \n",
        "  '''\n",
        "\n",
        "  def __init__(self,n_vocab,n_embed,hidden_size,output_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(n_vocab+1,n_embed) ## n_vocab is unique words in dictionary ## n_embed is hyperparameter\n",
        "     # input & output will has batch size as 1s dimension. e.g. (batch, time_step/seq_len, input_size)\n",
        "     ## n_layers default is 1 if 2 which means stacking\n",
        "    self.rnn = nn.RNN(n_embed, hidden_size, num_layers = 1, batch_first = True)\n",
        "    self.fc =  nn.Linear(hidden_size,output_size)   \n",
        "\n",
        "  def forward(self,x):\n",
        "    '''\n",
        "    We have to run all over once on whole input sequence (many-to-one)\n",
        "    input-size = 1*10 we want output size =[1,1,2]   \n",
        "    '''\n",
        "    x = x # input batch_size * seq_length\n",
        "    batch_size = x.size(0) \n",
        "    #print('Batch Size is',batch_size)\n",
        "    x = self.embedding(x) # batch-size x seq_length x embedding_dimension\n",
        "    x,hidden =self.rnn(x)   #batch-size x seq_length x hidden_size\n",
        "    out = self.fc(hidden.squeeze(0))  ## x[:,-1,:]  should be equals to hidden.squeeze(0)\n",
        "    out = torch.sigmoid(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDYohMngacM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## model\n",
        "n_vocab = len(char_to_int) ## 28\n",
        "n_embed = 100\n",
        "hidden_size = 8\n",
        "output_size =1\n",
        "model = RNN(n_vocab,n_embed, hidden_size,output_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZTlJTSLTiZY",
        "colab_type": "code",
        "outputId": "9bafb097-7b61-40a7-92a6-eb0a6df00345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model\n",
        "#model(input_features)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(29, 100)\n",
              "  (rnn): RNN(100, 8, batch_first=True)\n",
              "  (fc): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8SXlYTORHQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nqsGvcRRJFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsTfmmB7RegV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "90c349e9-a153-42dc-e95c-23af9d7bc523"
      },
      "source": [
        "n_iter = 20\n",
        "for epoch in range(n_iter):\n",
        "  optimizer.zero_grad()\n",
        "  prediction = model(input_feature).squeeze(1)\n",
        "  loss = criterion(prediction, label_tensor)\n",
        "  acc = binary_accuracy(prediction, label_tensor)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 2 == 0:\n",
        "    print('epoch',epoch,'loss',loss.item(),'accuracy',acc)\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 loss 0.6896332502365112 accuracy tensor(0.5000)\n",
            "epoch 2 loss 0.6895902156829834 accuracy tensor(0.5000)\n",
            "epoch 4 loss 0.6895471215248108 accuracy tensor(0.5000)\n",
            "epoch 6 loss 0.6895040273666382 accuracy tensor(0.5000)\n",
            "epoch 8 loss 0.6894609928131104 accuracy tensor(0.5000)\n",
            "epoch 10 loss 0.6894180178642273 accuracy tensor(0.5000)\n",
            "epoch 12 loss 0.6893749237060547 accuracy tensor(0.5000)\n",
            "epoch 14 loss 0.6893319487571716 accuracy tensor(0.5000)\n",
            "epoch 16 loss 0.689288854598999 accuracy tensor(0.5000)\n",
            "epoch 18 loss 0.689245879650116 accuracy tensor(0.5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJoK8MDeUNqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}